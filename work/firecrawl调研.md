#### 1. 用户请求 API（如 /v0/scrape）

- /scrape - 单页网页组曲
- /crawl  - 站点级爬取（递归抓取多个页面）
- //crawl/status/:jobId - 插曲爬取任务状态
- /crawl/cancel/:jobId - 取消爬取任务
- /search - 网页内容查询

#### 2. 参数校验、鉴权、额度检查

- 对参数的合法性校验
- 用户身份鉴权
- 查询用户身份和额度
- 判断用户的url是非在i

#### 3. 任务入队，分配唯一 jobId

#### 4. 爬虫引擎抓取网页内容（HTML/Markdown/截图/元数据）

#### 5. 如需结构化抽取，自动拼接 prompt/schema，调用 LLM

#### 6. 结果处理、异常修正、计费

#### 7. 返回结构化数据/原始内容/截图等

