#### 1. 用户请求 API（如 /v0/scrape）

- 

#### 2. 参数校验、鉴权、额度检查

#### 3. 任务入队，分配唯一 jobId

#### 4. 爬虫引擎抓取网页内容（HTML/Markdown/截图/元数据）

#### 5. 如需结构化抽取，自动拼接 prompt/schema，调用 LLM

#### 6. 结果处理、异常修正、计费

#### 7. 返回结构化数据/原始内容/截图等

