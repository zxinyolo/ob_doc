> 以下步骤前提:
>
> 1.两台机器,每台机器八张4090显卡,每张显卡24G
>
> 2.部署模型为unsloth/DeepSeek-R1-Distill-Llama-70B

#### 步骤1: 拉取大模型

每台机器都需要拉取大模型(一台下载后可以使用scp传输到其它机器),存放位置一致,比如/data下

```shell
cd /data
huggingface-cli download unsloth/DeepSeek-R1-Distill-Llama-70B --local-dir ./deepseek-r1-70B
```



#### 步骤2: 安装docker

每台机器都需要

如果docker 镜像默认存储路径空间不够需要更换docker镜像存储路径

```shell
#安装 nvidia-docker：
sudo apt-get install nvidia-docker2

#然后重启 Docker：
sudo systemctl restart docker
```



#### 步骤3: docker拉取vllm官方镜像

每台机器都需要拉取

```shell
docker pull vllm/vllm-openai:latest
```



#### 步骤4: 编写运行docker镜像脚本

每台机器都需要,存储路径一致,比如/data/docker_data/run_cluster.sh

```shell
#!/bin/bash

# Ensure there are enough arguments
if [ $# -lt 4 ]; then
    echo "Usage: $0 docker_image head_node_address --head|--worker path_to_hf_home [additional_args...]"
    exit 1
fi

# Assign variables
DOCKER_IMAGE="$1"
HEAD_NODE_ADDRESS="$2"
NODE_TYPE="$3"  # --head or --worker
PATH_TO_HF_HOME="$4"
shift 4

# Additional arguments are passed to the docker command
ADDITIONAL_ARGS=("$@")

# Validate the node type
if [ "${NODE_TYPE}" != "--head" ] && [ "${NODE_TYPE}" != "--worker" ]; then
    echo "Error: Node type must be --head or --worker"
    exit 1
fi

# Define the Ray command based on node type
RAY_START_CMD="ray start --block"
if [ "${NODE_TYPE}" == "--head" ]; then
    RAY_START_CMD+=" --head --port=6379"
else
    RAY_START_CMD+=" --address=${HEAD_NODE_ADDRESS}:6379"
fi

# Docker run command
docker run -d \
    --entrypoint /bin/bash \
    --network host \
    --name node \
    --shm-size 10.24g \
    --gpus all \
    -v "${PATH_TO_HF_HOME}:/root/.cache/huggingface" \
    "${ADDITIONAL_ARGS[@]}" \
    "${DOCKER_IMAGE}" -c "
    ${RAY_START_CMD} &
    tail -f /dev/null"  # Keep the container running

```



#### 步骤5: 运行run_cluster.sh脚本启动docker 容器

需要注意: 主节点和从节点运行的命令不一样

```shell
# 这里10.100.1.205 是主机器, 10.100.1.209是从机器
# 主机器运行
sudo bash run_cluster.sh vllm/vllm-openai 10.100.1.205 --head /data/deepseek-r1-70B -v /data/deepseek-r1-70B:/data/deepseek-r1-70B -e GLOO_SOCKET_IFNAME=ens6f0np0 -e NCCL_SOCKET_IFNAME=ens6f0np0 -e VLLM_HOST_IP=10.100.1.205
# 从机器运行
bash run_cluster.sh vllm/vllm-openai 10.100.1.205 --worker /data/deepseek-r1-70B -v /data/deepseek-r1-70B:/data/deepseek-r1-70B -e GLOO_SOCKET_IFNAME=ens6f0np0 -e NCCL_SOCKET_IFNAME=ens6f0np0 -e VLLM_HOST_IP=10.100.1.209

#  vllm/vllm-openai   镜像名称
#  10.100.1.205 主机器ip
#  --head 代表是主机器
#  --worker 代表从机器
#  /data/deepseek-r1-70B  模型路径
# -v /data/deepseek-r1-70B:/data/deepseek-r1-70B 宿主机本地模型映射到容器内
#  -e GLOO_SOCKET_IFNAME=ens6f0np0 服务器ip对应的网卡名称
#  -e NCCL_SOCKET_IFNAME=ens6f0np0 服务器ip对应的网卡名称
#  -e VLLM_HOST_IP=10.100.1.205 当前机器ip

```



#### 步骤6: 进入容器内运行vllm serve

检查ray的状态

```shell
Node status
---------------------------------------------------------------
Active:
 1 node_9cf41952b3e88a4a5580615bbeaf7af0c1d5e941eb165370452d550f
 1 node_e5b96489189c386cc1b7f5cbc00dc598319e4d65f67378c75e09a29c
Pending:
 (no pending nodes)
Recent failures:
 (no failures)

Resources
---------------------------------------------------------------
Usage:
 0.0/384.0 CPU
 0/16.0 GPU (16.0 used of 16.0 reserved in placement groups)
 0B/977.33GiB memory
 0B/19.46GiB object_store_memory

# 0/16.0 GPU (16.0 used of 16.0 reserved in placement groups) 代表集群中有16张显卡
# 1 node_9cf41952b3e88a4a5580615bbeaf7af0c1d5e941eb165370452d550f
	1 node_e5b96489189c386cc1b7f5cbc00dc598319e4d65f67378c75e09a29c 代表加主节点有两个节点 也就是有两台机器

```

两台机器都需要进入容器运行:

```shell
export VLLM_HOST_IP=10.100.1.209  对应机器写对应机器的ip
export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
```

主机器运行此命令:

```shell
vllm serve /data/deepseek-r1-70B --port 8080 --tensor-parallel-size 4 --pipeline-parallel-size 4 --dtype float16


# /data/deepseek-r1-70B 模型存放路径
#　--port 8080　http监听端口 客户端可以通过 http://<服务器IP>:8080/v1/completions 访问模型 API
# --tensor-parallel-size 4  张量并行数量 表示使用 4 张 GPU 进行张量并行
# --pipeline-parallel-size 4 流水线并行 表示使用 4 张 GPU 进行流水线并行
# --dtype float16 指定计算使用的数据精度


出现以下信息代表模型加载成功:
Started server process
Waiting for application startup
Application startup complete
```

模型加载完成之后就可以访问模型API

```shell
curl http://localhost:8080/v1/completions \
-H "Content-Type: application/json" \
-d '{
"model": "/data/deepseek-r1-70B",
"prompt": "你是谁",
"max_tokens": 2048
}'
```

当有api访问时可以查看每台机器gpu使用情况:

```shell
watch -n 1 nvidia-smi
# 返回
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA GeForce RTX 4090        Off |   00000000:16:00.0 Off |                  Off |
| 30%   33C    P0            131W /  450W |   21556MiB /  24564MiB |     45%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA GeForce RTX 4090        Off |   00000000:38:00.0 Off |                  Off |
| 30%   34C    P0            144W /  450W |   21556MiB /  24564MiB |     53%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA GeForce RTX 4090        Off |   00000000:49:00.0 Off |                  Off |
| 30%   35C    P0            140W /  450W |   21556MiB /  24564MiB |     56%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA GeForce RTX 4090        Off |   00000000:5A:00.0 Off |                  Off |
| 30%   32C    P0            133W /  450W |   21556MiB /  24564MiB |     53%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   4  NVIDIA GeForce RTX 4090        Off |   00000000:98:00.0 Off |                  Off |
| 30%   36C    P0            134W /  450W |   22070MiB /  24564MiB |     61%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   5  NVIDIA GeForce RTX 4090        Off |   00000000:B8:00.0 Off |                  Off |
| 30%   33C    P0            159W /  450W |   22066MiB /  24564MiB |     68%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   6  NVIDIA GeForce RTX 4090        Off |   00000000:C8:00.0 Off |                  Off |
| 30%   34C    P0            132W /  450W |   22066MiB /  24564MiB |     73%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   7  NVIDIA GeForce RTX 4090        Off |   00000000:D8:00.0 Off |                  Off |
| 30%   34C    P0            139W /  450W |   22066MiB /  24564MiB |     74%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A      6863      C   ray::RayWorkerWrapper                       21536MiB |
|    1   N/A  N/A      6865      C   ray::RayWorkerWrapper.execute_method        21536MiB |
|    2   N/A  N/A      6864      C   ray::RayWorkerWrapper.execute_method        21536MiB |
|    3   N/A  N/A      6866      C   ray::RayWorkerWrapper.execute_method        21536MiB |
|    4   N/A  N/A      6868      C   ray::RayWorkerWrapper.execute_method        22052MiB |
|    5   N/A  N/A      6862      C   ray::RayWorkerWrapper.execute_method        22048MiB |
|    6   N/A  N/A      6867      C   ray::RayWorkerWrapper.execute_method        22048MiB |
|    7   N/A  N/A      6869      C   ray::RayWorkerWrapper.execute_method        22048MiB |
+-----------------------------------------------------------------------------------------+

```



#### 测试结果

- 并发500个问题













