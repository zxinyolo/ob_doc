#### 安装docker

```shell
#安装 nvidia-docker：
sudo apt-get install nvidia-docker2

#然后重启 Docker：
sudo systemctl restart docker
```

- docker安装失败?

  ```shell
  // 添加官方 NVIDIA Docker 仓库
  distribution=$(. /etc/os-release;echo $ID$VERSION_ID)  # 获取 Ubuntu 版本
  curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg
  curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list | \
      sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
      sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list
      
  sudo apt update
  
  sudo apt install -y nvidia-docker2
  
  sudo systemctl restart docker
  ```

  



#### 本地拉取大模型

```shell
huggingface-cli download unsloth/DeepSeek-R1-Distill-Llama-70B --local-dir ./deepseek-r1-70B
```

- 下载的目录没有权限?

  ```shell
  // 获取下载目录存储权限
  sudo chown -R mars:mars /data
  sudo chmod -R 775 /data
  ```



#### docker拉取镜像

```shell
docker pull vllm/vllm-openai:latest
```



#### 运行脚本

```shell
#!/bin/bash

# Ensure there are enough arguments
if [ $# -lt 4 ]; then
    echo "Usage: $0 docker_image head_node_address --head|--worker path_to_hf_home [additional_args...]"
    exit 1
fi

# Assign variables
DOCKER_IMAGE="$1"
HEAD_NODE_ADDRESS="$2"
NODE_TYPE="$3"  # --head or --worker
PATH_TO_HF_HOME="$4"
shift 4

# Additional arguments are passed to the docker command
ADDITIONAL_ARGS=("$@")

# Validate the node type
if [ "${NODE_TYPE}" != "--head" ] && [ "${NODE_TYPE}" != "--worker" ]; then
    echo "Error: Node type must be --head or --worker"
    exit 1
fi

# Define the Ray command based on node type
RAY_START_CMD="ray start --block"
if [ "${NODE_TYPE}" == "--head" ]; then
    RAY_START_CMD+=" --head --port=6379"
else
    RAY_START_CMD+=" --address=${HEAD_NODE_ADDRESS}:6379"
fi

# Docker run command
docker run -d \
    --entrypoint /bin/bash \
    --network host \
    --name node \
    --shm-size 10.24g \
    --gpus all \
    -v "${PATH_TO_HF_HOME}:/root/.cache/huggingface" \
    "${ADDITIONAL_ARGS[@]}" \
    "${DOCKER_IMAGE}" -c "
    ${RAY_START_CMD} &
    tail -f /dev/null"  # Keep the container running

```



#### 运行

```shell
sudo bash run_cluster.sh vllm/vllm-openai 10.100.1.205 --head /data/deepseek-r1-70B -v /data/deepseek-r1-70B:/data/deepseek-r1-70B -e GLOO_SOCKET_IFNAME=ens6f0np0 -e NCCL_SOCKET_IFNAME=ens6f0np0 -e VLLM_HOST_IP=10.100.1.205
```

```shell
bash run_cluster.sh vllm/vllm-openai 10.100.1.205 --worker /data/deepseek-r1-70B -v /data/deepseek-r1-70B:/data/deepseek-r1-70B -e GLOO_SOCKET_IFNAME=ens6f0np0 -e NCCL_SOCKET_IFNAME=ens6f0np0 -e VLLM_HOST_IP=10.100.1.209
```

#### 进容器设置环境变量

```shell
export VLLM_HOST_IP=10.100.1.209


vllm serve /data/deepseek-r1-70B --port 8080 --tensor-parallel-size 4 --pipeline-parallel-size 4 --dtype float16
```



