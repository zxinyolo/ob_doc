### 名词解析

1. **Token**

   在 NLP（自然语言处理）中，**token 是文本的最小计算单元**，它可以是：

   ​	•	**一个单词**（如 "hello" → 1 个 token）

   ​	•	**一个子词**（如 "unhappy" → [un, happy] 2 个 tokens，BPE 分词）

   ​	•	**一个标点符号**（如 "," → 1 个 token）

   ​	•	**一个单个字符**（某些语言，如中文，每个字符可能是 1 个 token）



2. **参数大小**

   在**大型语言模型（LLM）**（如 GPT-4、Gemini、Llama）中，**参数大小（Number of Parameters）** 代表**模型内部的可训练变量（权重和偏置）**的总数

​		**模型参数的作用**

​			**存储知识**：模型通过大量文本训练，参数会学习到词汇、语法、上下文等信息。

​			**调整输出**：不同参数值会影响模型对输入文本的理解和生成效果。

​			**控制复杂度**：参数越多，模型可以学习更复杂的模式，但训练和推理成本也更高。

3. **LangChain**框架

   **LangChain**框架是一个开源工具,充分利用大型语言模型的强大能力,来开发各种下游应用.目标思维各种大型语言模型应用提供通用接口,从而简化应用程序的开发流程.可以能够让语言模型与其它数据来源连接

   

   LangChain和核心组件:

   - 模型的输入和输出：与语言模型交互的接口
   - 数据连接：与特定应用程序数据进行交互的接口
   - 链: 将组件组合实现端到端应用.比如后续我们会将搭建检索问答链来完成检索问答
   - 记忆: 用于链的多次运行之间持久化应用程序状态
   - 代理: 扩展模型的推理能力, 用于复杂的应用的调用序列
   - 回调：扩展模型的推理能力，用于复杂的应用的调用序列



4. **RAG(Retrieval-Augmented Generation)搭建**

   ![](https://raw.githubusercontent.com/zxinyolo/images/main/image-20250217153711967.png)



​	实现原理: 加载本地文档-> 读取文本->文本分割->文本向量化->在文本向量中匹配出与问句向量最相似的top K个->匹配出的文本作为上下文和问题一起添加到Prompt中->提交给LLM生成回答



**词向量:** 

​	在机器学习和自然语言处理(NLP)中, 词向量(Embeddings)使用一种将结构化数据,如单次,句子或者整个文档,转化为实数向量的计数

​	![image-20250217155130134](https://raw.githubusercontent.com/zxinyolo/images/main/image-20250217155130134.png)

**如何把相近的词用向量表示？**

- 语料库训练: Embedding的向量是通过对大量文本数据进行训练得到的,通常是通过无监督学习方法.最常见的训练方法包括Word2Vec,Glove和FastText

  - Word2Vec: Word2Vec主要有两种训练方法:

    - Skip-gram: 通过给定一个单词,预测周围的上下文单词.
    - CBOW(Continuous Bag of Words): 通过给定上下文预测中间的目标词

    通过这种训练, 模型会学会根据上下文来调整每个词的向量,使得相似上下文中的词(比如"狗"和"猫")具有相似的向量
  
  - GloVe: GloVe是另一种常用的词嵌入方法,它基于词与词之间的共现矩阵进行训练.通过捕捉全局统计信息来学习词与词之间的关系,而不像Word2Vec那样完全依赖上下文

- 相似性度量：一旦词汇被转换成向量，计算词语之间的相似性就变得非常简单，追常见的度量方法是余弦相似度，通过计算两个向量的夹角来衡量它们的相似性：
  $$
  \text{cosine similarity} = \frac{A \cdot B}{\|A\| \|B\|}
  $$
  其中A和B是两个词的向量表示, ⋅ 是向量的点积，$\|A\|$ 和 $\|B\|$是它们的模

  如果两个词的向量越接近,余弦相似度的值就越接近1,表示它们在语义上越相似



**词向量的优势**

​	词向量在RAG里的优势主要有两点:

​		语义检索更准确:　词向量能表达语义，相似度计算可以找到语义相近的内容，比传统关键词匹配更精准

​		垮模态能力更强：　不同类型的数据（文字，图片，音频等）都可以转向向量，方便统一检索，实现跨模态查询



4. Agent(基于大模型的智能体)

   **Agents的诞生：从LLMs到自主行动**

   - 知识局限性: LLMs的知识仅限于训练数据,无法获取实时信息和外部知识库
   - 行动局限性: LLMs无法与外界交互,无法执行实际操作.为了克服这些局限性, 谷歌的研究人员在《New whitepaper Agents》详细论述了“Agent”的概念，将LLMs与工具和编排层相结合，赋予其自主行动的能力。

   **Agent核心组件**

   1. 模型(Model):
      - 角色: 作为Agent的大脑,负责理解用户的输出,进行推理和规划,并选择合适的工具进行执行
      - 类型: 常用的模型包括ReAct、Chain-of-Thought、Tree-of-Thought等.它们提供不同的推理框架,帮助Agent进行多轮交互和决策
      - 重要性: 模型是Agent的核心,其推理能力决定了Agent的行动效率和准确性
   2. 工具(Tools):
      - 角色: 作为Agent与外界交互的桥梁,允许Agent访问外部数据和服务,执行各种任务
      - 类型: 工具可以提供各种API,例如数据库查询,搜索引擎,代码执行器,邮件发送器等
      - 重要性: 工具拓展了Agent的能力,使其能够执行更复杂的任务
   3. 编排层(**Orchestration Layer**):
      - 角色:负责管理Agent的内部状态,协调模型和工具的使用,并根据目标指导Agent的行动
      - 类型:编排层可以使用各种推理框架，例如ReAct、Chain-of-Thought等,帮助Agent进行规划和决策
      - 重要性: 编排层是Agent的指挥中心,负责协调各个组件,确保Agent的行动符合目标

   ![image-20250219142730164](https://raw.githubusercontent.com/zxinyolo/images/main/image-20250219142730164.png)

​	

​	**Agents的运作机制: 从输入到输出**

​	接收输入: agent接收用户的指令或问题

​	理解输入: 模型理解用户的意图,并提取关键信息

​	推理规划: 模型根据用户输入和当前状态,进行推理和规划,确定下一步行动

​	选择工具: 模型根据目标选择合适的工具

​	执行行动: agent使用工具执行行动,例如查询数据库,发送邮件等

​	获取结果: agent获取工具执行的结果

​	输出结果: agent将结果输出给用户,或进行下一步行动

